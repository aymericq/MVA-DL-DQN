{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "import skvideo.io\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from keras.models import Sequential,model_from_json\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import sgd\n",
    "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MiniProject on Deep Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
    "\n",
    "\\begin{equation*}\n",
    "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
    "\\end{equation*}\n",
    "\n",
    "where: \n",
    "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "We note the $Q$-function:\n",
    "\n",
    "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "Thus, the optimal Q function is:\n",
    "\\begin{equation*}\n",
    "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
    "\\end{equation*}\n",
    "\n",
    "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The environment, the agent and the game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def act(self, act):\n",
    "        \"\"\"\n",
    "        One can act on the environment and obtain its reaction:\n",
    "        - the new state\n",
    "        - the reward of the new state\n",
    "        - should we continue the game?\n",
    "\n",
    "        :return: state, reward, game_over\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"\n",
    "        Reinitialize the environment to a random state and returns\n",
    "        the original state\n",
    "\n",
    "        :return: state\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Visualize in the console or graphically the current state\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
    "\n",
    "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
    "\n",
    "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
    "\n",
    "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(object):\n",
    "    def __init__(self, epsilon=0.1, n_action=4):\n",
    "        self.epsilon = epsilon\n",
    "        self.n_action = n_action\n",
    "    \n",
    "    def set_epsilon(self,e):\n",
    "        self.epsilon = e\n",
    "\n",
    "    def act(self,s,train=True):\n",
    "        \"\"\" This function should return the next action to do:\n",
    "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
    "        if train:\n",
    "            if np.random.rand() <= self.epsilon:\n",
    "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
    "            else:\n",
    "                a = self.learned_act(s)\n",
    "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
    "            a = self.learned_act(s)\n",
    "\n",
    "        return a\n",
    "\n",
    "    def learned_act(self,s):\n",
    "        \"\"\" Act via the policy of the agent, from a given state s\n",
    "        it proposes an action a\"\"\"\n",
    "        pass\n",
    "\n",
    "    def reinforce(self, s, n_s, a, r, game_over_):\n",
    "        \"\"\" This function is the core of the learning algorithm. \n",
    "        It takes as an input the current state s_, the next state n_s_\n",
    "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
    "        \n",
    "        Its goal is to learn a policy.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" This function returns basic stats if applicable: the\n",
    "        loss and/or the model\"\"\"\n",
    "        pass\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\" This function allows to restore a model\"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 1__:\n",
    "Explain the function act. Why is ```epsilon``` essential?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter epsilon controls the exploration vs exploitation. It means the bigger $\\epsilon$ gets, the more random the agent acts. This allows to explore more states, and thus not possibly miss a bigger reward with a riskier policy. Conversely, when $\\epsilon$ is low, the agent relies on what it already learned, and acts according to what is going to maximize its reward, given the positions it already visited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
    "\n",
    "```python\n",
    "\n",
    "epoch = 300\n",
    "env = Environment()\n",
    "agent = Agent()\n",
    "\n",
    "\n",
    "# Number of won games\n",
    "score = 0\n",
    "loss = 0\n",
    "\n",
    "\n",
    "for e in range(epoch):\n",
    "    # At each epoch, we restart to a fresh game and get the initial state\n",
    "    state = env.reset()\n",
    "    # This assumes that the games will end\n",
    "    game_over = False\n",
    "\n",
    "    win = 0\n",
    "    lose = 0\n",
    "    \n",
    "    while not game_over:\n",
    "        # The agent performs an action\n",
    "        action = agent.act(state)\n",
    "\n",
    "        # Apply an action to the environment, get the next state, the reward\n",
    "        # and if the games end\n",
    "        prev_state = state\n",
    "        state, reward, game_over = env.act(action)\n",
    "\n",
    "        # Update the counters\n",
    "        if reward > 0:\n",
    "            win = win + reward\n",
    "        if reward < 0:\n",
    "            lose = lose -reward\n",
    "\n",
    "        # Apply the reinforcement strategy\n",
    "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "\n",
    "    # Save as a mp4\n",
    "    if e % 10 == 0:\n",
    "        env.draw(e)\n",
    "\n",
    "    # Update stats\n",
    "    score += win-lose\n",
    "\n",
    "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "          .format(e, epoch, loss, win, lose, win-lose))\n",
    "    agent.save()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The game, *eat cheese*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
    "\n",
    "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
    "        grid_size = grid_size+4\n",
    "        self.grid_size = grid_size\n",
    "        self.max_time = max_time\n",
    "        self.temperature = temperature\n",
    "\n",
    "        #board on which one plays\n",
    "        self.board = np.zeros((grid_size,grid_size))\n",
    "        self.position = np.zeros((grid_size,grid_size))\n",
    "\n",
    "        # coordinate of the cat\n",
    "        self.x = 0\n",
    "        self.y = 1\n",
    "\n",
    "        # self time\n",
    "        self.t = 0\n",
    "\n",
    "        self.scale=16\n",
    "\n",
    "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "    def draw(self,e):\n",
    "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
    "\n",
    "    def get_frame(self,t):\n",
    "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
    "        b[self.board>0,0] = 256\n",
    "        b[self.board < 0, 2] = 256\n",
    "        b[self.x,self.y,:]=256\n",
    "        b[-2:,:,:]=0\n",
    "        b[:,-2:,:]=0\n",
    "        b[:2,:,:]=0\n",
    "        b[:,:2,:]=0\n",
    "        \n",
    "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "        self.to_draw[t,:,:,:]=b\n",
    "\n",
    "\n",
    "    def act(self, action):\n",
    "        \"\"\"This function returns the new state, reward and decides if the\n",
    "        game ends.\"\"\"\n",
    "\n",
    "        self.get_frame(int(self.t))\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "\n",
    "        self.position[self.x, self.y] = 1\n",
    "        if action == 0:\n",
    "            # Go right\n",
    "            if self.x == self.grid_size-3:\n",
    "                self.x = self.x-1\n",
    "            else:\n",
    "                self.x = self.x + 1\n",
    "        elif action == 1:\n",
    "            # Go left\n",
    "            if self.x == 2:\n",
    "                self.x = self.x+1\n",
    "            else:\n",
    "                self.x = self.x-1\n",
    "        elif action == 2:\n",
    "            # Go up\n",
    "            if self.y == self.grid_size - 3:\n",
    "                self.y = self.y - 1\n",
    "            else:\n",
    "                self.y = self.y + 1\n",
    "        elif action == 3:\n",
    "            # Go down\n",
    "            if self.y == 2:\n",
    "                self.y = self.y + 1\n",
    "            else:\n",
    "                self.y = self.y - 1\n",
    "        else:\n",
    "            RuntimeError('Error: action not recognized')\n",
    "\n",
    "        self.t = self.t + 1\n",
    "        reward = self.board[self.x, self.y]\n",
    "        self.board[self.x, self.y] = 0\n",
    "        game_over = self.t > self.max_time\n",
    "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
    "\n",
    "        return state, reward, game_over\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
    "\n",
    "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
    "\n",
    "\n",
    "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
    "\n",
    "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
    "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
    "\n",
    "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
    "\n",
    "\n",
    "        malus[bonus>0]=0\n",
    "\n",
    "        self.board = bonus + malus\n",
    "\n",
    "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
    "        self.position[0:2,:]= -1\n",
    "        self.position[:,0:2] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.position[-2:, :] = -1\n",
    "        self.board[self.x,self.y] = 0\n",
    "        self.t = 0\n",
    "\n",
    "        state = np.concatenate((\n",
    "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
    "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
    "\n",
    "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
    "        return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following elements are important because they correspond to the hyper parameters for this project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=50 # set small when debugging\n",
    "epochs_test=10 # set small when debugging\n",
    "\n",
    "# display videos\n",
    "def display_videos(name):\n",
    "    video = io.open(name, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return '''<video alt=\"test\" controls>\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent(Agent):\n",
    "    def __init__(self):\n",
    "        super(RandomAgent, self).__init__()\n",
    "        pass\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return np.random.randint(0, self.n_action, size=1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(agent,env,epochs,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "        \n",
    "    for e in range(epochs):\n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will end\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            # loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
    "        ##### FILL IN HERE\n",
    "        \n",
    "        # Save as a mp4\n",
    "        env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score = score + win-lose\n",
    "\n",
    "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
    "              .format(win, lose, score/(1+e)))\n",
    "    print('Final score: '+str(score/epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 4.5/4.0. Average score (0.5)\n",
      "Win/lose count 1.0/2.0. Average score (-0.25)\n",
      "Win/lose count 2.5/2.0. Average score (0.0)\n",
      "Win/lose count 0.5/3.0. Average score (-0.625)\n",
      "Win/lose count 1.5/1.0. Average score (-0.4)\n",
      "Final score: -0.4\n"
     ]
    }
   ],
   "source": [
    "# Initialize the game\n",
    "env = Environment(grid_size=10, max_time=100,temperature=0.1)\n",
    "\n",
    "# Initialize the agent!\n",
    "agent = RandomAgent()\n",
    "\n",
    "epochs_test = 5\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "test(agent,env,epochs_test,prefix='random')\n",
    "# Video('random0.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us assume here that $T=\\infty$.\n",
    "\n",
    "***\n",
    "__Question 5__ Let $\\pi$ be a policy, show that:\n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
    "\\end{equation*}\n",
    "\n",
    "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
    "\n",
    "\\begin{equation*}\n",
    "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
    "\\end{equation*}\n",
    "Finally, deduce that a plausible objective is:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
    "\n",
    "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
    "\n",
    "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
    "\n",
    "3. Store $(s_t,a_t,s_{t+1})$;\n",
    "\n",
    "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
    "\n",
    "***\n",
    "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory(object):\n",
    "    def __init__(self, max_memory=100):\n",
    "        self.max_memory = max_memory\n",
    "        self.index = 0\n",
    "        self.memory = list()\n",
    "\n",
    "    def remember(self, m):\n",
    "        if len(self.memory) < self.max_memory:\n",
    "            self.memory.append(m)\n",
    "        else:\n",
    "            self.memory[self.index] = m\n",
    "        self.index = (self.index + 1)%self.max_memory\n",
    "\n",
    "    def random_access(self):\n",
    "        return self.memory[np.random.randint(len(self.memory))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "The pipeline we will use for training is given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # decreasing epsilon-greedy policy\n",
    "        agent.set_epsilon(agent.epsilon*0.95)\n",
    "        print(agent.epsilon)\n",
    "        \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state, action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(Agent):\n",
    "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16, n_state=2):\n",
    "        super(DQN, self).__init__(epsilon = epsilon)\n",
    "\n",
    "        # Discount for Q learning\n",
    "        self.discount = 0.9\n",
    "        \n",
    "        self.grid_size = grid_size\n",
    "        \n",
    "        # number of state\n",
    "        self.n_state = n_state\n",
    "\n",
    "        # Memory\n",
    "        self.memory = Memory(memory_size)\n",
    "        \n",
    "        # Batch size when learning\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def learned_act(self, s):\n",
    "        return np.argmax(self.model.predict(np.array([s]), batch_size=1))\n",
    "\n",
    "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
    "        # Two steps: first memorize the states, second learn from the pool\n",
    "\n",
    "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
    "        \n",
    "        input_states = np.zeros((self.batch_size, 5, 5, self.n_state))\n",
    "        target_q = np.zeros((self.batch_size, 4))\n",
    "        \n",
    "        # EDIT STARTS HERE\n",
    "        \n",
    "        for i in range(self.batch_size):\n",
    "            state, new_state, action, reward, game_over = self.memory.random_access()\n",
    "            input_states[i,:,:,:] = state\n",
    "\n",
    "            # if done, make our target reward\n",
    "            target = reward\n",
    "\n",
    "            if not game_over:\n",
    "                # predict the future discounted reward\n",
    "                target = reward + self.discount * \\\n",
    "                    np.amax(self.model.predict(np.array([new_state]), batch_size=1))\n",
    "\n",
    "            # make the agent to approximately map\n",
    "            # the current state to future discounted reward\n",
    "            # We'll call that target_f\n",
    "            target_q[i,:] = self.model.predict(np.array([state]), batch_size=1)\n",
    "            target_q[i,action] = reward\n",
    "        \n",
    "        \"\"\"\n",
    "        for i in range(self.batch_size):\n",
    "            ######## FILL IN\n",
    "            \n",
    "            if game_over_:\n",
    "                ######## FILL IN\n",
    "            else:\n",
    "                ######## FILL IN\n",
    "        ######## FILL IN\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
    "        target_q = np.clip(target_q, -3, 3)\n",
    "\n",
    "        l = self.model.train_on_batch(input_states, target_q)\n",
    "\n",
    "\n",
    "        return l\n",
    "\n",
    "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
    "        self.model.save_weights(name_weights, overwrite=True)\n",
    "        with open(name_model, \"w\") as outfile:\n",
    "            json.dump(self.model.to_json(), outfile)\n",
    "            \n",
    "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
    "        with open(name_model, \"r\") as jfile:\n",
    "            model = model_from_json(json.load(jfile))\n",
    "        model.load_weights(name_weights)\n",
    "        model.compile(\"sgd\", \"mse\")\n",
    "        self.model = model\n",
    "\n",
    "            \n",
    "class DQN_FC(DQN):\n",
    "    def __init__(self, *args, lr=0.1,**kwargs):\n",
    "        super(DQN_FC, self).__init__(*args, **kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        model = keras.Sequential()\n",
    "        model.add(Flatten(input_shape=(5,5, self.n_state)))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-1f077705c100>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnvironment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQN_FC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fc_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fc_train10.mp4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-69e39d0138d5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(agent, env, epoch, prefix)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;31m# Apply the reinforcement strategy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreinforce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgame_over\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;31m# Save as a mp4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ac368d5e0bf2>\u001b[0m in \u001b[0;36mreinforce\u001b[0;34m(self, s_, n_s_, a_, r_, game_over_)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m# the current state to future discounted reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;31m# We'll call that target_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mtarget_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mtarget_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_DQN/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1462\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/miniconda3/envs/DL_DQN/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_DQN/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3748\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3749\u001b[0;31m         expand_composites=True)\n\u001b[0m\u001b[1;32m   3750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_DQN/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mpack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites)\u001b[0m\n\u001b[1;32m    448\u001b[0m   \"\"\"\n\u001b[1;32m    449\u001b[0m   \u001b[0mis_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_sequence_or_composite\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexpand_composites\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flat_sequence must be a sequence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/DL_DQN/lib/python3.7/site-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mIsSequenceOrComposite\u001b[0;34m(o)\u001b[0m\n\u001b[1;32m   2526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m     \"\"\"\n\u001b[0;32m-> 2528\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIsSequenceOrComposite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mIsCompositeTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "train(agent, env, epochs_train, prefix='fc_train')\n",
    "HTML(display_videos('fc_train10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(DQN):\n",
    "    def __init__(self, *args,lr=0.1,**kwargs):\n",
    "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
    "        \n",
    "        # NN Model\n",
    "        model = keras.Sequential()\n",
    "        # model.add(Flatten(input_shape=(5,5, self.n_state)))\n",
    "        model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "        model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(4, activation='linear'))\n",
    "        \n",
    "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
    "        self.model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=50 # set small when debugging\n",
    "epochs_test=10 # set small when debugging\n",
    "\n",
    "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=0.1, epsilon = 0.3, memory_size=2000, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.285\n",
      "Epoch 000/050 | Loss 0.0001 | Win/lose count 8.5/5.0 (3.5)\n",
      "0.27075\n",
      "Epoch 001/050 | Loss 0.0011 | Win/lose count 10.0/8.0 (2.0)\n",
      "0.25721249999999996\n",
      "Epoch 002/050 | Loss 0.0002 | Win/lose count 14.5/7.0 (7.5)\n",
      "0.24435187499999994\n",
      "Epoch 003/050 | Loss 0.0012 | Win/lose count 12.5/5.0 (7.5)\n",
      "0.23213428124999994\n",
      "Epoch 004/050 | Loss 0.0002 | Win/lose count 15.0/9.0 (6.0)\n",
      "0.22052756718749994\n",
      "Epoch 005/050 | Loss 0.0002 | Win/lose count 12.5/9.0 (3.5)\n",
      "0.20950118882812493\n",
      "Epoch 006/050 | Loss 0.0160 | Win/lose count 15.5/10.0 (5.5)\n",
      "0.19902612938671868\n",
      "Epoch 007/050 | Loss 0.0008 | Win/lose count 9.5/10.0 (-0.5)\n",
      "0.18907482291738273\n",
      "Epoch 008/050 | Loss 0.0035 | Win/lose count 10.5/8.0 (2.5)\n",
      "0.1796210817715136\n",
      "Epoch 009/050 | Loss 0.0005 | Win/lose count 7.0/8.0 (-1.0)\n",
      "0.1706400276829379\n",
      "Epoch 010/050 | Loss 0.0084 | Win/lose count 13.5/4.0 (9.5)\n",
      "0.162108026298791\n",
      "Epoch 011/050 | Loss 0.0014 | Win/lose count 2.0/2.0 (0.0)\n",
      "0.15400262498385145\n",
      "Epoch 012/050 | Loss 0.0074 | Win/lose count 11.5/4.0 (7.5)\n",
      "0.14630249373465887\n",
      "Epoch 013/050 | Loss 0.0016 | Win/lose count 16.0/5.0 (11.0)\n",
      "0.1389873690479259\n",
      "Epoch 014/050 | Loss 0.0011 | Win/lose count 12.5/4.0 (8.5)\n",
      "0.13203800059552961\n",
      "Epoch 015/050 | Loss 0.0069 | Win/lose count 18.5/6.0 (12.5)\n",
      "0.12543610056575313\n",
      "Epoch 016/050 | Loss 0.0026 | Win/lose count 21.0/4.0 (17.0)\n",
      "0.11916429553746546\n",
      "Epoch 017/050 | Loss 0.0006 | Win/lose count 14.0/7.0 (7.0)\n",
      "0.11320608076059219\n",
      "Epoch 018/050 | Loss 0.0018 | Win/lose count 17.5/4.0 (13.5)\n",
      "0.10754577672256257\n",
      "Epoch 019/050 | Loss 0.0004 | Win/lose count 16.5/2.0 (14.5)\n",
      "0.10216848788643444\n",
      "Epoch 020/050 | Loss 0.0002 | Win/lose count 16.0/3.0 (13.0)\n",
      "0.09706006349211271\n",
      "Epoch 021/050 | Loss 0.0060 | Win/lose count 15.5/3.0 (12.5)\n",
      "0.09220706031750707\n",
      "Epoch 022/050 | Loss 0.0014 | Win/lose count 19.0/4.0 (15.0)\n",
      "0.08759670730163172\n",
      "Epoch 023/050 | Loss 0.0007 | Win/lose count 13.0/6.0 (7.0)\n",
      "0.08321687193655013\n",
      "Epoch 024/050 | Loss 0.0003 | Win/lose count 12.5/6.0 (6.5)\n",
      "0.07905602833972261\n",
      "Epoch 025/050 | Loss 0.0003 | Win/lose count 15.5/6.0 (9.5)\n",
      "0.07510322692273648\n",
      "Epoch 026/050 | Loss 0.0003 | Win/lose count 13.5/1.0 (12.5)\n",
      "0.07134806557659966\n",
      "Epoch 027/050 | Loss 0.0025 | Win/lose count 17.5/3.0 (14.5)\n",
      "0.06778066229776968\n",
      "Epoch 028/050 | Loss 0.0004 | Win/lose count 16.0/1.0 (15.0)\n",
      "0.06439162918288119\n",
      "Epoch 029/050 | Loss 0.0003 | Win/lose count 14.5/0 (14.5)\n",
      "0.061172047723737126\n",
      "Epoch 030/050 | Loss 0.0014 | Win/lose count 14.5/3.0 (11.5)\n",
      "0.058113445337550265\n",
      "Epoch 031/050 | Loss 0.0003 | Win/lose count 7.5/1.0 (6.5)\n",
      "0.05520777307067275\n",
      "Epoch 032/050 | Loss 0.0001 | Win/lose count 8.0/2.0 (6.0)\n",
      "0.05244738441713911\n",
      "Epoch 033/050 | Loss 0.0002 | Win/lose count 4.0/0 (4.0)\n",
      "0.04982501519628215\n",
      "Epoch 034/050 | Loss 0.0057 | Win/lose count 9.0/3.0 (6.0)\n",
      "0.04733376443646804\n",
      "Epoch 035/050 | Loss 0.0006 | Win/lose count 7.0/3.0 (4.0)\n",
      "0.04496707621464464\n",
      "Epoch 036/050 | Loss 0.0012 | Win/lose count 9.0/3.0 (6.0)\n",
      "0.042718722403912404\n",
      "Epoch 037/050 | Loss 0.0003 | Win/lose count 8.5/0 (8.5)\n",
      "0.04058278628371678\n",
      "Epoch 038/050 | Loss 0.0002 | Win/lose count 11.0/1.0 (10.0)\n",
      "0.03855364696953094\n",
      "Epoch 039/050 | Loss 0.0002 | Win/lose count 7.0/0 (7.0)\n",
      "0.03662596462105439\n",
      "Epoch 040/050 | Loss 0.0003 | Win/lose count 5.0/0 (5.0)\n",
      "0.03479466639000167\n",
      "Epoch 041/050 | Loss 0.0002 | Win/lose count 8.0/0 (8.0)\n",
      "0.033054933070501585\n",
      "Epoch 042/050 | Loss 0.0002 | Win/lose count 3.5/0 (3.5)\n",
      "0.03140218641697651\n",
      "Epoch 043/050 | Loss 0.0001 | Win/lose count 15.0/0 (15.0)\n",
      "0.02983207709612768\n",
      "Epoch 044/050 | Loss 0.0002 | Win/lose count 11.5/0 (11.5)\n",
      "0.028340473241321294\n",
      "Epoch 045/050 | Loss 0.0001 | Win/lose count 4.5/1.0 (3.5)\n",
      "0.02692344957925523\n",
      "Epoch 046/050 | Loss 0.0001 | Win/lose count 3.0/0 (3.0)\n",
      "0.025577277100292468\n",
      "Epoch 047/050 | Loss 0.0001 | Win/lose count 3.0/0 (3.0)\n",
      "0.024298413245277845\n",
      "Epoch 048/050 | Loss 0.0001 | Win/lose count 1.5/0 (1.5)\n",
      "0.02308349258301395\n",
      "Epoch 049/050 | Loss 0.0002 | Win/lose count 7.0/0 (7.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(agent,env,epochs_train,prefix='cnn_train')\n",
    "HTML(display_videos('cnn_train10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.set_epsilon(0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test of the CNN\n",
      "Win/lose count 4.0/3.0. Average score (1.0)\n",
      "Win/lose count 2.0/4.0. Average score (-0.5)\n",
      "Win/lose count 1.5/6.0. Average score (-1.8333333333333333)\n",
      "Win/lose count 4.5/4.0. Average score (-1.25)\n",
      "Win/lose count 3.5/3.0. Average score (-0.9)\n",
      "Win/lose count 4.5/1.0. Average score (-0.16666666666666666)\n",
      "Win/lose count 2.0/2.0. Average score (-0.14285714285714285)\n",
      "Win/lose count 3.0/2.0. Average score (0.0)\n",
      "Win/lose count 5.5/8.0. Average score (-0.2777777777777778)\n",
      "Win/lose count 4.5/1.0. Average score (0.1)\n",
      "Final score: 0.1\n",
      "Test of the FC\n",
      "Win/lose count 4.0/4.0. Average score (0.0)\n",
      "Win/lose count 4.0/7.0. Average score (-1.5)\n",
      "Win/lose count 5.5/6.0. Average score (-1.1666666666666667)\n",
      "Win/lose count 2.5/5.0. Average score (-1.5)\n",
      "Win/lose count 1.0/3.0. Average score (-1.6)\n",
      "Win/lose count 6.0/8.0. Average score (-1.6666666666666667)\n",
      "Win/lose count 3.5/5.0. Average score (-1.6428571428571428)\n",
      "Win/lose count 5.0/7.0. Average score (-1.6875)\n",
      "Win/lose count 3.5/9.0. Average score (-2.111111111111111)\n",
      "Win/lose count 7.5/6.0. Average score (-1.75)\n",
      "Final score: -1.75\n"
     ]
    }
   ],
   "source": [
    "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
    "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
    "\n",
    "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
    "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
    "print('Test of the CNN')\n",
    "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
    "print('Test of the FC')\n",
    "test(agent_fc,env,epochs_test,prefix='fc_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(display_videos('cnn_test8.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HTML(display_videos('fc_test10.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
    "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
    "2. Append via the environment a new state that describes if a cell has been visited or not\n",
    "\n",
    "***\n",
    "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_explore(agent,env,epoch,prefix=''):\n",
    "    # Number of won games\n",
    "    score = 0\n",
    "    loss = 0\n",
    "\n",
    "    for e in range(epoch):\n",
    "        # decreasing epsilon-greedy policy\n",
    "        agent.set_epsilon(agent.epsilon*0.95)\n",
    "        print(agent.epsilon)\n",
    "        \n",
    "        # At each epoch, we restart to a fresh game and get the initial state\n",
    "        state = env.reset()\n",
    "        # This assumes that the games will terminate\n",
    "        game_over = False\n",
    "\n",
    "        win = 0\n",
    "        lose = 0\n",
    "\n",
    "        while not game_over:\n",
    "            # The agent performs an action\n",
    "            action = agent.act(state)\n",
    "\n",
    "            # Apply an action to the environment, get the next state, the reward\n",
    "            # and if the games end\n",
    "            prev_state = state\n",
    "            state, reward, game_over = env.act(action, train=True)\n",
    "\n",
    "            # Update the counters\n",
    "            if reward > 0:\n",
    "                win = win + reward\n",
    "            if reward < 0:\n",
    "                lose = lose -reward\n",
    "\n",
    "            # Apply the reinforcement strategy\n",
    "            loss = agent.reinforce(prev_state, state, action, reward, game_over)\n",
    "\n",
    "        # Save as a mp4\n",
    "        if e % 10 == 0:\n",
    "            env.draw(prefix+str(e))\n",
    "\n",
    "        # Update stats\n",
    "        score += win-lose\n",
    "\n",
    "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
    "              .format(e, epoch, loss, win, lose, win-lose))\n",
    "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
    "\n",
    "\n",
    "class EnvironmentExploring(Environment):\n",
    "    def __init__(self, grid_size=10, max_time=500, temperature=0.1, train=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.visited = np.zeros((grid_size,grid_size))\n",
    "    \n",
    "    def act(self, action, train=False):\n",
    "        state, reward, game_over = super().act(action)\n",
    "        \n",
    "        if train:\n",
    "            reward -= 0.1*self.visited[self.x, self.y]\n",
    "        \n",
    "        self.visited[self.x, self.y] = 1\n",
    "        \n",
    "        state = np.concatenate((\n",
    "            state,\n",
    "            self.visited.reshape(\n",
    "                self.grid_size, self.grid_size,1\n",
    "            )[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :],\n",
    "        ), axis=2)\n",
    "        \n",
    "        return state, reward, game_over\n",
    "    \n",
    "    def reset(self):\n",
    "        state = super().reset()\n",
    "        \n",
    "        self.visited = np.zeros((self.grid_size,self.grid_size))\n",
    "        \n",
    "        state = np.concatenate((\n",
    "            state,\n",
    "            self.visited.reshape(\n",
    "                self.grid_size, self.grid_size,1\n",
    "            )[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :],\n",
    "        ), axis=2)\n",
    "        \n",
    "        return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "size = 13\n",
    "T=200\n",
    "temperature=0.3\n",
    "epochs_train=50 # set small when debugging\n",
    "epochs_test=10 # set small when debugging\n",
    "\n",
    "# Training\n",
    "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
    "agent = DQN_CNN(size, lr=.1, epsilon = 0.4, memory_size=2000, batch_size = 128, n_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38\n",
      "Epoch 000/050 | Loss 0.0066 | Win/lose count 2.5/56.30000000000042 (-53.80000000000042)\n",
      "0.361\n",
      "Epoch 001/050 | Loss 0.0033 | Win/lose count 4.5/48.90000000000043 (-44.40000000000043)\n",
      "0.34295\n",
      "Epoch 002/050 | Loss 0.0046 | Win/lose count 5.5/47.800000000000374 (-42.300000000000374)\n",
      "0.32580249999999994\n",
      "Epoch 003/050 | Loss 0.0043 | Win/lose count 7.0/50.600000000000385 (-43.600000000000385)\n",
      "0.30951237499999995\n",
      "Epoch 004/050 | Loss 0.0028 | Win/lose count 2.5/52.20000000000044 (-49.70000000000044)\n",
      "0.2940367562499999\n",
      "Epoch 005/050 | Loss 0.0078 | Win/lose count 3.0/45.80000000000036 (-42.80000000000036)\n",
      "0.2793349184374999\n",
      "Epoch 006/050 | Loss 0.0032 | Win/lose count 3.0/48.8000000000004 (-45.8000000000004)\n",
      "0.2653681725156249\n",
      "Epoch 007/050 | Loss 0.0010 | Win/lose count 2.0/46.100000000000385 (-44.100000000000385)\n",
      "0.2520997638898436\n",
      "Epoch 008/050 | Loss 0.0016 | Win/lose count 1.5/45.60000000000038 (-44.10000000000038)\n",
      "0.23949477569535144\n",
      "Epoch 009/050 | Loss 0.0020 | Win/lose count 2.5/46.10000000000037 (-43.60000000000037)\n",
      "0.22752003691058387\n",
      "Epoch 010/050 | Loss 0.0007 | Win/lose count 4.0/46.20000000000036 (-42.20000000000036)\n",
      "0.21614403506505467\n",
      "Epoch 011/050 | Loss 0.0011 | Win/lose count 8.0/45.000000000000334 (-37.000000000000334)\n",
      "0.20533683331180191\n",
      "Epoch 012/050 | Loss 0.0016 | Win/lose count 3.0/48.100000000000406 (-45.100000000000406)\n",
      "0.1950699916462118\n",
      "Epoch 013/050 | Loss 0.0033 | Win/lose count 5.0/48.8000000000004 (-43.8000000000004)\n",
      "0.18531649206390122\n",
      "Epoch 014/050 | Loss 0.0022 | Win/lose count 3.5/46.60000000000036 (-43.10000000000036)\n",
      "0.17605066746070616\n",
      "Epoch 015/050 | Loss 0.0004 | Win/lose count 4.5/48.60000000000035 (-44.10000000000035)\n",
      "0.16724813408767084\n",
      "Epoch 016/050 | Loss 0.0004 | Win/lose count 5.0/42.400000000000325 (-37.400000000000325)\n",
      "0.1588857273832873\n",
      "Epoch 017/050 | Loss 0.0013 | Win/lose count 6.5/46.20000000000038 (-39.70000000000038)\n",
      "0.15094144101412293\n",
      "Epoch 018/050 | Loss 0.0004 | Win/lose count 3.0/44.80000000000037 (-41.80000000000037)\n",
      "0.14339436896341679\n",
      "Epoch 019/050 | Loss 0.0017 | Win/lose count 3.0/46.60000000000035 (-43.60000000000035)\n",
      "0.13622465051524593\n",
      "Epoch 020/050 | Loss 0.0011 | Win/lose count 4.0/47.6000000000004 (-43.6000000000004)\n",
      "0.12941341798948364\n",
      "Epoch 021/050 | Loss 0.0021 | Win/lose count 5.0/44.90000000000037 (-39.90000000000037)\n",
      "0.12294274709000945\n",
      "Epoch 022/050 | Loss 0.0017 | Win/lose count 6.5/48.00000000000038 (-41.50000000000038)\n",
      "0.11679560973550897\n",
      "Epoch 023/050 | Loss 0.0011 | Win/lose count 5.0/48.300000000000395 (-43.300000000000395)\n",
      "0.11095582924873351\n",
      "Epoch 024/050 | Loss 0.0004 | Win/lose count 4.0/44.60000000000035 (-40.60000000000035)\n",
      "0.10540803778629683\n",
      "Epoch 025/050 | Loss 0.0016 | Win/lose count 4.5/42.20000000000033 (-37.70000000000033)\n",
      "0.10013763589698198\n",
      "Epoch 026/050 | Loss 0.0003 | Win/lose count 4.0/43.70000000000034 (-39.70000000000034)\n",
      "0.09513075410213287\n",
      "Epoch 027/050 | Loss 0.0016 | Win/lose count 3.5/47.20000000000037 (-43.70000000000037)\n",
      "0.09037421639702622\n",
      "Epoch 028/050 | Loss 0.0005 | Win/lose count 5.0/46.80000000000038 (-41.80000000000038)\n",
      "0.0858555055771749\n",
      "Epoch 029/050 | Loss 0.0030 | Win/lose count 3.5/44.50000000000035 (-41.00000000000035)\n",
      "0.08156273029831615\n",
      "Epoch 030/050 | Loss 0.0020 | Win/lose count 3.0/46.10000000000037 (-43.10000000000037)\n",
      "0.07748459378340034\n",
      "Epoch 031/050 | Loss 0.0005 | Win/lose count 4.5/45.300000000000345 (-40.800000000000345)\n",
      "0.07361036409423032\n",
      "Epoch 032/050 | Loss 0.0021 | Win/lose count 6.0/44.40000000000033 (-38.40000000000033)\n",
      "0.0699298458895188\n",
      "Epoch 033/050 | Loss 0.0003 | Win/lose count 3.0/47.30000000000039 (-44.30000000000039)\n",
      "0.06643335359504285\n",
      "Epoch 034/050 | Loss 0.0023 | Win/lose count 2.5/43.50000000000035 (-41.00000000000035)\n",
      "0.0631116859152907\n",
      "Epoch 035/050 | Loss 0.0006 | Win/lose count 3.0/47.90000000000039 (-44.90000000000039)\n",
      "0.059956101619526164\n",
      "Epoch 036/050 | Loss 0.0004 | Win/lose count 2.5/48.2000000000004 (-45.7000000000004)\n",
      "0.056958296538549856\n",
      "Epoch 037/050 | Loss 0.0005 | Win/lose count 3.5/48.000000000000384 (-44.500000000000384)\n",
      "0.05411038171162236\n",
      "Epoch 038/050 | Loss 0.0004 | Win/lose count 3.0/44.40000000000036 (-41.40000000000036)\n",
      "0.051404862626041235\n",
      "Epoch 039/050 | Loss 0.0003 | Win/lose count 5.5/45.70000000000038 (-40.20000000000038)\n",
      "0.04883461949473917\n",
      "Epoch 040/050 | Loss 0.0002 | Win/lose count 5.5/44.80000000000036 (-39.30000000000036)\n",
      "0.04639288852000221\n",
      "Epoch 041/050 | Loss 0.0008 | Win/lose count 5.0/43.900000000000325 (-38.900000000000325)\n",
      "0.044073244094002095\n",
      "Epoch 042/050 | Loss 0.0012 | Win/lose count 4.5/46.10000000000039 (-41.60000000000039)\n",
      "0.04186958188930199\n",
      "Epoch 043/050 | Loss 0.0004 | Win/lose count 5.0/43.00000000000033 (-38.00000000000033)\n",
      "0.039776102794836884\n",
      "Epoch 044/050 | Loss 0.0018 | Win/lose count 0.5/48.10000000000041 (-47.60000000000041)\n",
      "0.03778729765509504\n",
      "Epoch 045/050 | Loss 0.0006 | Win/lose count 2.5/47.20000000000039 (-44.70000000000039)\n",
      "0.03589793277234028\n",
      "Epoch 046/050 | Loss 0.0005 | Win/lose count 4.0/47.100000000000385 (-43.100000000000385)\n",
      "0.034103036133723265\n",
      "Epoch 047/050 | Loss 0.0005 | Win/lose count 4.5/47.40000000000039 (-42.90000000000039)\n",
      "0.0323978843270371\n",
      "Epoch 048/050 | Loss 0.0002 | Win/lose count 3.5/46.30000000000039 (-42.80000000000039)\n",
      "0.030777990110685244\n",
      "Epoch 049/050 | Loss 0.0013 | Win/lose count 5.0/42.40000000000033 (-37.40000000000033)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_explore(agent, env, epochs_train, prefix='cnn_train_explore_2')\n",
    "HTML(display_videos('cnn_train_explore10.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Win/lose count 6.5/0. Average score (6.5)\n",
      "Win/lose count 3.5/1.0. Average score (4.5)\n",
      "Win/lose count 3.0/2.0. Average score (3.3333333333333335)\n",
      "Win/lose count 4.5/3.0. Average score (2.875)\n",
      "Win/lose count 2.0/0. Average score (2.7)\n",
      "Win/lose count 4.0/1.0. Average score (2.75)\n",
      "Win/lose count 6.5/0. Average score (3.2857142857142856)\n",
      "Win/lose count 4.0/2.0. Average score (3.125)\n",
      "Win/lose count 3.5/2.0. Average score (2.9444444444444446)\n",
      "Win/lose count 4.0/1.0. Average score (2.95)\n",
      "Final score: 2.95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls>\n",
       "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
       "             </video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation\n",
    "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
    "HTML(display_videos('cnn_test_explore9.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "***\n",
    "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_DQN",
   "language": "python",
   "name": "dl_dqn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
